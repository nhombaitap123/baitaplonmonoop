{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhombaitap123/baitaplonmonoop/blob/master/IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nOpcX8-e8YWY",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_3LBOUH1_TKt",
        "outputId": "c7bfcd4c-481e-4502-c869-caac66fc2c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zHipSR5D_fmd",
        "outputId": "d73f263c-f8f2-4fa8-cedc-9d1ea50eec80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/'My Drive'/IMDB"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/IMDB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_fpgdaE8YWe",
        "outputId": "93d309bf-4e5b-468d-ff18-622f72449635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "movie_reviews = pd.read_csv(\"IMDB_Dataset.csv\")\n",
        "movie_reviews.isnull().values.any()\n",
        "movie_reviews.shape"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eDzfmzpJ8YWh",
        "outputId": "6e1e0012-f925-45d7-d026-0ddac7142e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "movie_reviews.head()"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brS8ohXA8YWk",
        "outputId": "3f49a8fe-c308-4367-d509-2ba5a12b76fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "movie_reviews[\"review\"][3]"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cQ9wayDA8YWn"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZDkd1Ko8YWo",
        "colab": {}
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n5Uv1y518YWr",
        "colab": {}
      },
      "source": [
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7EnpOw348YWu"
      },
      "source": [
        "### Store reviews in a new list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZTPkd3zH8YWu",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "sentences = list(movie_reviews['review'])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aQp_Nm9o8YWx",
        "outputId": "1ec69d64-14dc-4e0f-892f-34c467fbd27c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X[3]"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Basically there a family where little boy Jake thinks there a zombie in his closet his parents are fighting all the time This movie is slower than soap opera and suddenly Jake decides to become Rambo and kill the zombie OK first of all when you re going to make film you must Decide if its thriller or drama As drama the movie is watchable Parents are divorcing arguing like in real life And then we have Jake with his closet which totally ruins all the film expected to see BOOGEYMAN similar movie and instead watched drama with some meaningless thriller spots out of just for the well playing parents descent dialogs As for the shots with Jake just ignore them '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ip04wz4S8YW0"
      },
      "source": [
        "### Convert our labels into digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ht1sFf5w8YW1",
        "colab": {}
      },
      "source": [
        "y = movie_reviews['sentiment']\n",
        "\n",
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cRBPkL2m8YW4",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4-X4Jfyd8YW9"
      },
      "source": [
        "### Preparing the Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS_SUFw68YW-",
        "colab": {}
      },
      "source": [
        "#the Tokenizer class from the keras.preprocessing.text module to create a word-to-index dictionary\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JKVjDKE98YXA",
        "colab": {}
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "#We set the maximum size of each list to 100. You can try a different size. \n",
        "#The lists with size greater than 100 will be truncated to 100. For the lists that have length less than 100, \n",
        "#we will add 0 at the end of the list until it reaches the max length. This process is called padding.\n",
        "\n",
        "# maxlen = 100\n",
        "maxlen_train = max([len(s) for s in X_train])\n",
        "\n",
        "#X_train or X_test, you will see that all the lists have same length i.e. 100\n",
        "#vocabulary_size variable now contains a value 92547 which means that our corpus has 92547 unique words\n",
        "X_train_1 = pad_sequences(X_train, padding='post', maxlen=maxlen_train)\n",
        "X_test_1 = pad_sequences(X_test, padding='post', maxlen=maxlen_train)\n",
        "X_train_2 = pad_sequences(X_train, padding='post', maxlen=100)\n",
        "X_test_2 = pad_sequences(X_test, padding='post', maxlen=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jRNtkd1U8YXD",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uEpkZrjZLe4l",
        "colab": {}
      },
      "source": [
        "# embedding matrix where each row number will correspond to the index of the word in the corpus\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  embedding_vector = embeddings_dictionary.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "22d0ZkxU8YXM"
      },
      "source": [
        "### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EaW6Jthd8YXN",
        "colab": {}
      },
      "source": [
        "#Text Classification with Simple Neural Network\n",
        "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
        "model = Sequential()\n",
        "\n",
        "embedding_layer = Embedding(vocab_size, 100, input_length=maxlen_train, trainable=False)\n",
        "model.add(embedding_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "doWwq0ri8YXQ",
        "colab": {}
      },
      "source": [
        "#simple convolutional neural network with 1 convolutional layer and 1 pooling layer\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "  precision = precision_m(y_true, y_pred)\n",
        "  recall = recall_m(y_true, y_pred)\n",
        "  return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p_-Mbnb78YXT",
        "outputId": "e2a07870-4b7a-4ea8-b8d8-b5ae99b17078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 2004, 100)         9254700   \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 2000, 128)         64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_11 (Glo (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 9,320,129\n",
            "Trainable params: 65,429\n",
            "Non-trainable params: 9,254,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pSiIjKvg8YXV",
        "outputId": "54e4df7c-83ed-47cf-c1ae-3c97787d1c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#train our model and evaluate it on the training set\n",
        "history = model.fit(X_train_1, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
        "\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test_1, y_test, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/6\n",
            "32000/32000 [==============================] - 466s 15ms/step - loss: 0.6327 - acc: 0.6647 - f1_m: 0.6185 - precision_m: 0.6510 - recall_m: 0.6473 - val_loss: 0.5314 - val_acc: 0.7539 - val_f1_m: 0.7643 - val_precision_m: 0.7305 - val_recall_m: 0.8040\n",
            "Epoch 2/6\n",
            "32000/32000 [==============================] - 465s 15ms/step - loss: 0.4640 - acc: 0.7859 - f1_m: 0.7899 - precision_m: 0.7728 - recall_m: 0.8147 - val_loss: 0.4225 - val_acc: 0.8165 - val_f1_m: 0.8152 - val_precision_m: 0.8164 - val_recall_m: 0.8159\n",
            "Epoch 3/6\n",
            "19840/32000 [=================>............] - ETA: 2:42 - loss: 0.3715 - acc: 0.8427 - f1_m: 0.8432 - precision_m: 0.8310 - recall_m: 0.8603"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8cfaQ_KH8YXY",
        "colab": {}
      },
      "source": [
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Test precision\", precision)\n",
        "print(\"Test Recall\", recall)\n",
        "print(\"Test f1-score\", f1_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AMOqZci28YXc",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0IZz5DDO8YXg"
      },
      "source": [
        "### Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5UxC9T358YXh",
        "colab": {}
      },
      "source": [
        "#Text Classification with Simple Neural Network\n",
        "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "#The embedding layer will have an input length of 100, the output vector dimension will also be 100. \n",
        "#The vocabulary size will be 92547 words.\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=100 , trainable=False)\n",
        "model2.add(embedding_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xm-0MdhB8YXj",
        "colab": {}
      },
      "source": [
        "#simple convolutional neural network with 1 convolutional layer and 1 pooling layer\n",
        "model2.add(Conv1D(128, 5, activation='relu'))\n",
        "model2.add(GlobalMaxPooling1D())\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "  precision = precision_m(y_true, y_pred)\n",
        "  recall = recall_m(y_true, y_pred)\n",
        "  return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGLDm7af8YXm",
        "colab": {}
      },
      "source": [
        "print(model2.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lWQlFT_L8YXp",
        "colab": {}
      },
      "source": [
        "#train our model and evaluate it on the training set\n",
        "history2 = model2.fit(X_train_2, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
        "\n",
        "loss, accuracy, f1_score, precision, recall = model2.evaluate(X_test_2, y_test, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R5FCp69P8YXu",
        "colab": {}
      },
      "source": [
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Test precision\", precision)\n",
        "print(\"Test Recall\", recall)\n",
        "print(\"Test f1-score\", f1_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3l0A-3hu8YXx",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history2.history['acc'])\n",
        "plt.plot(history2.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4KpKdOU-8YX0"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8cQe7Dta8YX1",
        "colab": {}
      },
      "source": [
        "instance = X[41244]\n",
        "print(instance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y1zAtXiK8YX3",
        "colab": {}
      },
      "source": [
        "instance = tokenizer.texts_to_sequences(instance)\n",
        "\n",
        "#pad our input sequence as we did for our corpus\n",
        "flat_list = []\n",
        "for sublist in instance:\n",
        "    for item in sublist:\n",
        "        flat_list.append(item)\n",
        "\n",
        "flat_list = [flat_list]\n",
        "\n",
        "instance_1 = pad_sequences(flat_list, padding='post', maxlen=maxlen_train)\n",
        "instance_2 = pad_sequences(flat_list, padding='post', maxlen=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZQnfjUSD8YX9",
        "colab": {}
      },
      "source": [
        "model.predict(instance_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z5Efqs2T8YYC",
        "colab": {}
      },
      "source": [
        "model2.predict(instance_2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}